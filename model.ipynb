{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "kERI2arS9HT-"
      },
      "outputs": [],
      "source": [
        "#importing all required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to download file of train data from google drive\n",
        "!gdown 17MjnQcrDmzrdN904aBejisgi1wRM9Kzk\n",
        "#to download file of test data from google drive\n",
        "!gdown 1wRwKiAiDhmDXQTFBn4jZYCYX_kIGvs46"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KK-3I78ARoZ",
        "outputId": "d6fcec69-5330-4427-ac30-e64a74199774"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17MjnQcrDmzrdN904aBejisgi1wRM9Kzk\n",
            "To: /content/train.csv\n",
            "100% 2.04M/2.04M [00:00<00:00, 157MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wRwKiAiDhmDXQTFBn4jZYCYX_kIGvs46\n",
            "To: /content/test.csv\n",
            "100% 3.89M/3.89M [00:00<00:00, 127MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to read csv file of train data and split it into Y and X train data\n",
        "TrainDataVerdicts=pd.read_csv(\"/content/train.csv\",usecols=[0])\n",
        "TrainData=pd.read_csv(\"/content/train.csv\",usecols=[1,2,3,4,5,6,7,8,9])\n",
        "#to read csv file of test data and split it into Y and X test data\n",
        "TestDataVerdicts=pd.read_csv(\"/content/test.csv\",usecols=[0])\n",
        "TestData=pd.read_csv(\"/content/test.csv\",usecols=[1,2,3,4,5,6,7,8,9])\n"
      ],
      "metadata": {
        "id": "ntdu59awFARV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building the neural network\n",
        "model=keras.Sequential()\n",
        "\n",
        "model.add(Dense(units=256,input_shape=[TrainData.shape[1]],activation='relu'))\n",
        "model.add(Dense(units=256,activation='relu'))\n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=256,activation='relu'))\n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=128,activation='relu'))\n",
        "model.add(Dense(units=64,activation='relu'))\n",
        "model.add(Dense(units=64,activation='relu'))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',loss='mae')\n",
        "losses=model.fit(TrainData,TrainDataVerdicts,validation_data=(TestData,TestDataVerdicts),batch_size=150,epochs=20)\n",
        "#epochs is the number of times we go through the training set. Notice that each time we run it, the error decreases. So the higher the epochs, the more the accuracy of our prediction. Yet, we should ensure an optimum value of epoc \n",
        "#batchsize tells us how many rows we are proccessing at a time.\n"
      ],
      "metadata": {
        "id": "Y3l2U34xJ8dl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b725631-5c60-4ea7-fe5d-0e5c7e7cde40"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 256)               2560      \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 212,673\n",
            "Trainable params: 212,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "219/219 [==============================] - 6s 19ms/step - loss: 88.1529 - val_loss: 29470.6348\n",
            "Epoch 2/20\n",
            "219/219 [==============================] - 5s 24ms/step - loss: 3.5623 - val_loss: 29459.2734\n",
            "Epoch 3/20\n",
            "219/219 [==============================] - 5s 25ms/step - loss: 1.2426 - val_loss: 29461.1562\n",
            "Epoch 4/20\n",
            "219/219 [==============================] - 6s 26ms/step - loss: 0.7613 - val_loss: 29460.5898\n",
            "Epoch 5/20\n",
            "219/219 [==============================] - 6s 25ms/step - loss: 0.6800 - val_loss: 29458.9590\n",
            "Epoch 6/20\n",
            "219/219 [==============================] - 5s 22ms/step - loss: 0.4792 - val_loss: 29460.1484\n",
            "Epoch 7/20\n",
            "219/219 [==============================] - 5s 24ms/step - loss: 0.4713 - val_loss: 29460.5371\n",
            "Epoch 8/20\n",
            "219/219 [==============================] - 5s 25ms/step - loss: 0.3875 - val_loss: 29460.6074\n",
            "Epoch 9/20\n",
            "219/219 [==============================] - 5s 22ms/step - loss: 0.3314 - val_loss: 29460.1660\n",
            "Epoch 10/20\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.2365 - val_loss: 29459.8223\n",
            "Epoch 11/20\n",
            "219/219 [==============================] - 5s 23ms/step - loss: 0.3489 - val_loss: 29459.7812\n",
            "Epoch 12/20\n",
            "219/219 [==============================] - 7s 30ms/step - loss: 0.2863 - val_loss: 29459.6738\n",
            "Epoch 13/20\n",
            "219/219 [==============================] - 5s 23ms/step - loss: 0.1985 - val_loss: 29460.2598\n",
            "Epoch 14/20\n",
            "219/219 [==============================] - 6s 26ms/step - loss: 0.2025 - val_loss: 29459.7500\n",
            "Epoch 15/20\n",
            "219/219 [==============================] - 6s 27ms/step - loss: 1.3764 - val_loss: 29468.6309\n",
            "Epoch 16/20\n",
            "219/219 [==============================] - 5s 23ms/step - loss: 0.8904 - val_loss: 29459.9531\n",
            "Epoch 17/20\n",
            "219/219 [==============================] - 7s 30ms/step - loss: 0.1442 - val_loss: 29459.9863\n",
            "Epoch 18/20\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.1247 - val_loss: 29459.9961\n",
            "Epoch 19/20\n",
            "219/219 [==============================] - 4s 18ms/step - loss: 0.1204 - val_loss: 29459.9414\n",
            "Epoch 20/20\n",
            "219/219 [==============================] - 6s 26ms/step - loss: 0.1132 - val_loss: 29460.0234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pred=model.predict(TestData)\n",
        "print(Pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMobrqD8bv-1",
        "outputId": "7a50e14a-4a4f-42a6-b282-cddd76c778f7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1842/1842 [==============================] - 4s 2ms/step\n",
            "[[0.97233033]\n",
            " [0.9739387 ]\n",
            " [0.99958014]\n",
            " ...\n",
            " [0.87675357]\n",
            " [0.9632833 ]\n",
            " [0.9800308 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=np.array(Pred)\n",
        "df=pd.DataFrame(prediction)\n",
        "df.to_csv(\"submission.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ek-62chrJQTe"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}